{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>K-Nearest Neighbors</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://ibm.box.com/shared/static/860wrw1jvullt57vl470fe7zikucwzzh.png\", height = 400, width = 400, align = 'right'>\n",
    "<img src = \"https://ibm.box.com/shared/static/f7wewzfjxozemzlhsf7tay1me0alyofa.png\", height = 150, width = 150, align = 'left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Welcome to Lab 2a of Machine Learning 101 with Python.</b>\n",
    "<p><b>Machine Learning is a form of artificial intelligence (AI), where the system can \"learn\" without explicitly being coded</b></p>\n",
    "\n",
    "In this lab exercise, you will learn the about the different evaluation models and metrics. You will be able to identify the strengths and weaknesses of each model and how to incorporate the Bias-Variance trade-off to them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notebook Commands Reminders:\n",
    "<ul>\n",
    "    <li>Run a cell: CTRL + ENTER</li>\n",
    "    <li>Create a cell above a cell: a</li>\n",
    "    <li>Create a cell below a cell: b</li>\n",
    "    <li>Change a cell to Markdown: m</li>\n",
    "    \n",
    "    <li>Change a cell to code: y</li>\n",
    "</ul>\n",
    "\n",
    "<b> If you are interested in more keyboard shortcuts, go to Help -> Keyboard Shortcuts </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> Before starting the lab, please run the following code in order to access the solutions </i> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style type=\"text/css\">\n",
       "    #ans:hover { background-color: black; }\n",
       "    #ans {padding: 6px; \n",
       "        background-color: white; \n",
       "        border: green 2px solid;\n",
       "        font-weight: bold}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style type=\"text/css\">\n",
    "    #ans:hover { background-color: black; }\n",
    "    #ans {padding: 6px; \n",
    "        background-color: white; \n",
    "        border: green 2px solid;\n",
    "        font-weight: bold}\n",
    "</style>\n",
    "\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors \n",
    "In this Lab you will load the Skulls dataset data, fit the data, and use K-Nearest Neighbors to predict a data point. But what is **K-Nearest Neighbors**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors** is an algorithm for supervised learning. Where the data is 'trained' with data points corresponding to their classification. Once a point is to be predicted, it takes into account the 'K' nearest points to it to determine it's classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's an visualization of the K-Nearest Neighbors algorithm.\n",
    "\n",
    "<img src = \"https://ibm.box.com/shared/static/mgkn92xck0z05v7yjq8pqziukxvc2461.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have data points of Class A and B. We want to predict what the star (test data point) is. If we consider a k value of 3 (3 nearest data points) we will obtain a prediction of Class B. Yet if we consider a k value of 6, we will obtain a prediction of Class A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sense, it is important to consider the value of k. But hopefully from this diagram, you should get a sense of what the K-Nearest Neighbors algorithm is. It considers the 'K' Nearest Neighbors (points) when it predicts the classification of the test point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## <u>Train/Test Split on the Skulls Dataset with K-Nearest Neighbors</u>\n",
    "\n",
    "### Import Libraries\n",
    "Import the Following Libraries:\n",
    "<ul>\n",
    "    <li> numpy (as np) </li>\n",
    "    <li> pandas </li>\n",
    "    <li> KNeighborsClassifier from sklearn.neighbors </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using my_data as the <b>skulls.csv</b> data read by panda, declare variables <b>X</b> as the <b>Feature Matrix</b> (<i>data of my_data</i>) and <b>y</b> as the <b>response vector</b> (<i>target</i>)<br>\n",
    "<i>Note: Use the <b>target</b> function for the <b>response vector</b> and the <b>removeColumns</b> function for the <b>Feature Matrix</b> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pandas.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/HSAUR/skulls.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(numpyArray, targetColumnIndex):\n",
    "    target_dict = dict()\n",
    "    target = list()\n",
    "    count = -1\n",
    "    for i in range(len(my_data.values)):\n",
    "        if my_data.values[i][targetColumnIndex] not in target_dict:\n",
    "            count += 1\n",
    "            target_dict[my_data.values[i][targetColumnIndex]] = count\n",
    "        target.append(target_dict[my_data.values[i][targetColumnIndex]])\n",
    "    return np.asarray(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column containing the target name since it doesn't contain numeric values.\n",
    "# Also remove the column that contains the row number\n",
    "# axis=1 means we are removing columns instead of rows.\n",
    "# Function takes in a pandas array and column numbers and returns a numpy array without\n",
    "# the stated columns\n",
    "def removeColumns(pandasArray, *column):\n",
    "    return pandasArray.drop(pandasArray.columns[[column]], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = removeColumns(my_data, 0, 1)\n",
    "y = target(my_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to perform <b>train/test split</b> we have to split the <b>X</b> and <b>y</b> into two different sets: The <b>training</b> and <b>testing</b> set. Luckily there is a sklearn function for just that!\n",
    "\n",
    "Import the <b>train_test_split</b> from <b>sklearn.cross_validation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now <b>train_test_split</b> will return <b>4</b> different parameters. We will name this <b>X_trainset</b>, <b>X_testset</b>, <b>y_trainset</b>, <b>y_testset</b>. The <b>train_test_split</b> will need the parameters <b>X</b>, <b>y</b>, <b>test_size=0.3</b>, and <b>random_state=7</b>. The <b>X</b> and <b>y</b> are the arrays required before the split, the <b>test_size</b> represents the ratio of the testing dataset, and the <b>random_state</b> ensures we obtain the same splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the shape of the training sets to see if they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainset.shape)\n",
    "print(y_trainset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the same with the testing sets! They should both match up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 4)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(X_testset.shape)\n",
    "print(y_testset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now similarly with the last lab, let's create declarations of <b>KNeighborsClassifier</b>. Except we will create <b>3</b> different ones:<br>\n",
    "<b>neigh</b>   -> <b>n_neighbors = 1</b> <br>\n",
    "<b>neigh23</b> -> <b>n_neighbors = 23</b> <br>\n",
    "<b>neigh90</b> -> <b>n_neighbors = 90</b> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = 1)\n",
    "neigh23 = KNeighborsClassifier(n_neighbors = 23)\n",
    "neigh90 = KNeighborsClassifier(n_neighbors = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fit each instance of <b>KNeighborsClassifier</b> with the <b>X_trainset</b> and <b>y_trainset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=90, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X_trainset, y_trainset)\n",
    "neigh23.fit(X_trainset, y_trainset)\n",
    "neigh90.fit(X_trainset, y_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in our last lab, we only predicted for <b>one</b> datapoint. However, you are able to predict with <b>multiple</b> datapoints. We can do this by just passing in the <b>y_testset</b> which contains multiple test points into a <b>predict</b> function of <b>KNeighborsClassifier</b>.\n",
    "\n",
    "Let's pass the <b>y_testset</b> in the <b>predict</b> function each instance of <b>KNeighborsClassifier</b> but store it's returned value into <b>pred</b>, <b>pred23</b>, <b>pred90</b> (corresponding to each of their names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = neigh.predict(X_testset)\n",
    "pred23 = neigh23.predict(X_testset)\n",
    "pred90 = neigh90.predict(X_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now let's compute neigh's <b>prediction accuracy</b>. We can do this by using the <b>metrics.accuracy_score</b> function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neigh's Accuracy:  0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print((\"Neigh's Accuracy: \"), metrics.accuracy_score(y_testset, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Let's do the same for the other instances of KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neigh23's Accuracy:  0.24444444444444444\n",
      "Neigh90's Accuracy:  0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "print((\"Neigh23's Accuracy: \"), metrics.accuracy_score(y_testset, pred23))\n",
    "print((\"Neigh90's Accuracy: \"), metrics.accuracy_score(y_testset, pred90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As shown, the accuracy of <b>neigh23</b> is the highest. When <b>n_neighbors = 1</b>, the model was <b>overfit</b> to the training data (<i>too specific</i>) and when <b>n_neighbors = 90</b>, the model was <b>underfit</b> (<i>too generalized</i>). In comparison, <b>n_neighbors = 23</b> had a <b>good balance</b> between <b>Bias</b> and <b>Variance</b>, creating a generalized model that neither <b>underfit</b> the data nor <b>overfit</b> it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <u>Train/Test Split on the Diabetes Dataset with Linear Regression</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now similar to the previous lab, we will be working with the Diabetes Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "Import the following libraries: \n",
    "    <ol>- <b>load_diabetes</b> from <b>sklearn.datasets</b></ol>\n",
    "    <ol>- <b>LinearRegression</b> from <b>sklearn.linear_model</b></ol>\n",
    "    <ol>- <b>matplotlib.pyplot</b> (as <b>plt</b>) </ol>\n",
    "<p>Ensure that you include <b>%matplotlib inline</b> to allow the plots to show up in the notebook </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes \n",
    "from sklearn.linear_model import LinearRegression \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an instance of the diabetes data set by using the <b>load_diabetes</b> function as a variable called <b>diabetes</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working with <b>one feature</b> like the last lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_X = diabetes.data[:, None, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an instance of the LinearRegression called LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use <b>diabetes_X</b> as the <b>Feature Matrix</b> and <b>diabetes.target</b> as the <b>response vector</b> and split it up using <b>train_test_split</b> function we imported earlier (<i>If you haven't, please import it</i>). The <b>train_test_split</b> function should have <b>test_size = 0.3</b> and a <b>random state = 7</b>. It should return values to <b>X_trainset</b>, <b>X_testset</b>, <b>y_trainset</b>, <b>y_testset</b> as in previous declarations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset, X_testset, y_trainset, y_testset = train_test_split(diabetes_X, diabetes.target, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the <b>LinReg</b> model using <b>X_trainset</b> and <b>y_trainset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.fit(X_trainset, y_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's <i>plot</i> the graph (similar to last time lab)\n",
    "<p> Use plt's <b>scatter</b> function to plot all the datapoints of <b>X_testset</b> and <b>y_testset</b> and color it <b>black</b> </p>\n",
    "<p> Use plt's <b>plot</b> function to plot the line of best fit with <b>X_testset</b> and <b>LinReg.predict(X_testset)</b>. Color it <b>blue</b> with a <b>linewidth</b> of <b>3</b>. </p> <br>\n",
    "<b>Note</b>: Please ignore the FutureWarning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x171d858a4a8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnX2UZGV95z+/6ekeGAcFagadAN3Nm2bBRIVW3IgmGzQISsCIWUi7YRNNx1ETskZP4Ew4QQ1nw8u6qxKFZiEC3QGBKHAIhiBikCTC9iAMIBkZsBsGRhwGQcYB5qV/+8e9zVT3VN26VXXf6/s555669dRzn/u7z637fZ77e97M3RFCCFFdFuVtgBBCiHSR0AshRMWR0AshRMWR0AshRMWR0AshRMWR0AshRMWR0AshRMWR0AshRMWR0AshRMVZnLcBAMuXL/fh4eG8zRBCiFKxZs2aZ9x9Rat4LYXezPYA7gSWhPGvd/e/MrOvAb8OPB9G/e/ufp+ZGfBF4ARgaxh+b9Q5hoeHmZqaamWKEEKIOsxsJk68ODX6l4HfdPctZtYP3GVm3wp/+4y7X78g/vHAYeF2NPDV8FMIIUQOtPTRe8CW8Gt/uEXNhHYScGV43PeBvc1sZfemCiGE6IRYjbFm1mdm9wE/BW5z97vDn841s7Vm9r/NbEkYtj/wRN3hG8KwhWmOmdmUmU1t2rSpi0sQQggRRSyhd/ed7v5m4ADgbWb2RuAs4JeBtwL7An8RRrdGSTRIc9zdR9x9ZMWKlm0JQgghOqSt7pXu/hzwXeC97r4xdM+8DPwd8LYw2gbgwLrDDgCeSsBWIYQQHdBS6M1shZntHe7vCbwb+I85v3vYy+Zk4MHwkJuA37eAtwPPu/vGVKwXQogcmJycZHh4mEWLFjE8PMzk5GTeJkUSp9fNSuAKM+sjKBiudfebzew7ZraCwFVzH/CxMP4tBF0r1xN0r/yD5M0WQoh8mJycZGxsjK1btwIwMzPD2NgYAKOjo3ma1hQrwlKCIyMjrn70QogyMDw8zMzM7t3Xh4aGmJ6eztQWM1vj7iOt4mkKBCGEaIPHH3+8rfAiIKEXQvQESfnVBwcH2wovAhJ6IUTlmfOrz8zM4O6v+NU7Eftzzz2XpUuXzgtbunQp5557blLmJo6EXghReVavXv1K4+kcW7duZfXq1W2nNTo6yvj4OENDQ5gZQ0NDjI+PF7YhFtQYK4ToARYtWkQjrTMzZmdnc7AoGdQYK4QQIWX0qyeJhF4IUXnK6FdPEgm9EKLylNGvniTy0QshREmRj14IIQQgoRdCiMojoRdCiIojoRdCiIojoReigJRtvnNRbOLMRy+EyJAyzncuio1q9EIUjCTnZRECJPRCFI4yzncuio2EXpSOqvuve31eFpE8EnpRKpKcV7yo9Pq8LCJ5JPSiVPSC/7rX52URyaO5bkSpqOq84kJ0gua6EZVE/msh2kdCL0qF/NdCtE9LoTezPczsHjO738weMrPPhuEHmdndZvaImX3dzAbC8CXh9/Xh78PpXoLoJeS/FqJ9WvrozcyAV7n7FjPrB+4CzgA+BXzD3a8xs4uB+939q2b2ceBX3f1jZnYq8AF3/69R55CPXggh2icxH70HbAm/9oebA78JXB+GXwGcHO6fFH4n/P3YsLAQQgiRA7F89GbWZ2b3AT8FbgMeBZ5z9x1hlA3A/uH+/sATAOHvzwO1JI0WQggRn1hC7+473f3NwAHA24D/1Cha+Nmo9r6bf8jMxsxsysymNm3aFNdeIUQGVH30ca/RVq8bd38O+C7wdmBvM5ub/fIA4KlwfwNwIED4+2uAZxukNe7uI+4+smLFis6sF0IkTi+MPu414vS6WWFme4f7ewLvBh4G7gBOCaOdDtwY7t8Ufif8/TtehFFZQohY9MLo414jznz0K4ErzKyPoGC41t1vNrMfAteY2V8DPwAuC+NfBlxlZusJavKnpmC3ECIlNHtm9Wgp9O6+FnhLg/DHCPz1C8NfAj6UiHVCiMwZHBxkZmamYbgoJxoZK4SYh0YfVw8JvRBiHhp9XD00e6UQQpQUzV4phBACkNALUXk0+CkZypyPcbpXCiFKytzgp7l+8XODnwD53Nug7PkoH70QFWZ4eLhhV8mhoSGmp6ezN6ikFDUf5aMXQmjwU0KUPR8l9EJUmCosvVgE33jZ81FCL0SFKfvgp6JMsFb2fMTdc9+OOuooF6LXmZiY8KGhITczHxoa8omJiUKnmwVDQ0NOMM35vG1oaChzW1rl40MPuZ96qvtNN2VnEzDlMTRWjbFCFICFvTogqDH2+ojURYsW0UijzIzZ2dkcLNqdm2+GE0+cH7ZhA+y/f+P4SaLGWCFKhKYGbkxRfePu8Dd/A2a7izzASy9lb1MUEnrRUxShYa8RZe/VkRZF841v2wanngqLFsFZZzWO87nPwSGHZGtXS+L4d9Le5KMXWTAxMeFLly6d5+tdunRpIXzWRfJFF40itDE8/bT7G97gHtTlG2+f/7z77Gy2dhHTR5+7yLuEXmREMzGdE9Q8Bb/IhVDSFEG443LffdHiDu7f+EZ+9knohViAmTUV+iIIa5kEsFPKUqBdf31rgb///rytjC/06nUjeoZmw9jrqdVqPPPMMxlZ1HsUdSoBCOT7s58NtmYccQTccQesWJGdXVGo140QC2jUsLeQzZs3F6aBtooUsdH5pZfg5JODBtZmIj86Ci+/DA8+WByRbwcJvSgkk5OTLF++HDPDzFi+fHnXAly/clIUvd6lMU3y6i7ZqLfVxo0wPAx77gk33tj4uAsuCGr6ExMwMND+OQpDHP9O2pt89KKeiYkJ7+/v382HPjAwkOho0YXpz21mlsg5eoV22hby8NHvfs6Rlv73f/zHbs+RTdsDaowVZaVV75ikqNVq6tLYJZ0IXNaNzrv+T6dFintfn/sPf9jtObL9L8UVejXGisLRbNg7JDv0XdMOdE+RG1chkPBFi84D/qJpnKOOgn/+Z9h3387Pk9dUDWqMFW1TFB9jlL82SV9uvc/ezBgaGpLIt0kRG1cBtm6F9743aGBtJvLLll3D9u0wNdWdyENxp2p4hVZVfuBA4A7gYeAh4Iww/BzgSeC+cDuh7pizgPXAOuC4VueQ6yZ/itS/OQsfvUiGoo3offxx99e+Ntr/Dp9M/L9deh89sBI4MtzfC/gRcHgo9J9uEP9w4H5gCXAQ8CjQF3UOCX3+FO2BnZiYmOdDr9VqEvkCUpQKwl13tRJ39/32+71U2wXyGPAWV+jb9tGb2Y3ARcA7gC3ufuGC388K3xT+Z/j9VuAcd//3ZmnKR58/ZZgOVhSTyclJVq9ezeOPP87g4CDnnntuZu6vyy+Hj3yk+e+vehXcdx8cemgm5mROKj56MxsG3gLcHQZ90szWmtnlZrZPGLY/8ETdYRvCsIVpjZnZlJlNbdq0qR0zRAoU3scoCsvo6CjT09PMzs4yPT2dusjPzsIZZwRTBDcT+Xe8A557DrZsqa7It0NsoTezZcA/AH/m7j8HvgocArwZ2Aj8r7moDQ7fraro7uPuPuLuIyvKONSsYhRtOlghFvLCC/Drvw59ffClLzWO84lPwI4dcNdd8JrXZGtfkYkl9GbWTyDyk+7+DQB3f9rdd7r7LHAp8LYw+gaCBtw5DgCeSs5kkQbqgSKKymOPBaL96lfDnXc2jnPJJYEn/qKLgoJAzKel0JuZAZcBD7v7F+rCV9ZF+wDwYLh/E3CqmS0xs4OAw4B7kjNZpEXUK3hRul6K9inrvbvjjsA9c8gh8POfN47zL/8SCPzYWLa2lY5WrbXAMQSul7XUdaUErgIeCMNvAlbWHbOaoLfNOuD4VudQr5tiU5SeFaJ9ynjvvvKV6N4ztZr7j3+ct5XFAI2MFUlR9NGPojlluXc7d8LHPw7j483jHHss3HADLFuWnV1FRyNjRWIUdfSjaE3R791zz8HRR8Pixc1F/s//PCgIvv3t5EW+rG6tdpHQi5ao62V5Keq9+9GPYMkS2GcfuKdJC94VVwTOmgsvnJvKIFnm5jqamZnB3ZmZmWFsbKySYi+hFy1R18vykta967QmfOutQQPrG94A27Y1jvPv/x4I/O//flcmtmT16tXzJrQD2Lp1azXXI4jjyE97U2Ns8emF9UyrStL3rpMG3i98IbqBdf/93Z94oiuz2qbZGsJlWo8ANcYKIdIgbgPv9u3w0Y/ClVc2T+t974PrrgtWecqasjRUR6HGWFF6eqWhrGy0auDdvBne9KZg6b1mIr96dTCVwc035yPy0GMuyTjV/rQ3uW7EQsrY/7tXaDbT6cqV7245g+Q11+Rt/XzK7pJErhtRZqrwWl1Vdl+Z60SCMZPNmZoKVnISySLXjSg1afX/7tQdJDfSLkZHR7nkknH23vs8gsp8Y5E/5BDYuDGoy0vkcyZOtT/tTa4bsZA0FkLp1B0kN9IuXnrJ/UMfinbPfPCDQTyRPiS1wlQWm4ReLCQNce208Mh79a0i+JF/8hP3ww6LFvjPf959djZz03oaCb0oPUkLXKf9ppPob93pteT9NnHvvdHiDu7f/GYmpogGSOhFYcmrhppXjb4bsc7rbeK661oL/Nq1qZogYiChF4UkzxpqXj76bsQ6y9Gbs7PuZ58dLe5HHOG+aVPipxYdIqEXhaSs/u5u3kK6Eess8mvrVvcTT4wW+NFR95dfTuyUIiEk9CIVunW7VGF+kXbpRqzTfAN68kn3Aw+MFvgLLuj6NCJFJPQicZIQnbxr9HnQbb4l3aZx993R4g7ut9zS1SlERkjoReIkIdJ59yLJiyJ0kZyYiBb3xYvdH344c7NEF0joRSzaEaCk3C5FEL1eYXbW/TOfiRb4kRH3Z5/N21LRCXGFXnPd9DC7z1kSzN43Pj7O6OjobvE1/0x5+MUv4AMfgNtuax7nox+Fr341WMZPlBPNddNjdDIXS7sr7LQzravmhsmHxx+H/fYL1lZtJvJf/nJQl7/0Uol8zxCn2p/2JtdNd3Tq9+7EFRPH7dKrfvg8+d73ot0z4P7tb+dtpUga5LrpHTp1qaTlipGLJzsuuyxwwTRj2TL4wQ/g0EOzs0lkR2KuGzM70MzuMLOHzewhMzsjDN/XzG4zs0fCz33CcDOzL5nZejNba2ZHdn85IopOp/RNa4WdtKYY7oY0XElJpxk3vdlZ+NM/DRbZbibyxxwDzz8PL7wgkRe0dt0AK4Ejw/29gB8BhwPnA2eG4WcC54X7JwDfAgx4O3B3q3PIddMd3Q7ISboHTJp95TuxNw1XUtJpxknv+efd3/nOaPfMJz/pvmNHx5clSgZpda8EbgTeA6wDVvquwmBduH8JcFpd/FfiNdsk9N2RlOgkJfrt2NPOOTu9zjQKnmZp9vX1dZR/UTauX+++117RAj8+3vGliBKTitADw8DjwKuB5xb89rPw82bgmLrw24GRqHQl9N3TrUinUUOds6dWq3mtVtvNtnbP2algpzHtQrM0O82/xun9l5YNrHfe2fEliAqQuNADy4A1wO+E35sJ/T82EPqjGqQ3BkwBU4ODg1nkiYggLXdLlJi3OufCwquZoLYS7Cxr9O2eo3E+fDxS3Jcvd5+e7th0USESFXqgH7gV+FRdmFw3FSKtycaiRDbqnI0KiGbx44hpFj76dvNvfhp9DuORAv/ud7u/8ELHJosKkpjQEzSqXgn8nwXhFzC/Mfb8cP99zG+MvafVOST0+ZNWjT5KzKPO2ey3henFFew0Gp3r0+zr62s7/4Jr3NvhnkiB//Sn3Xfu7NpcUUGSFPpjwj/tWuC+cDsBqBG4ZR4JP/f1XQXD3wKPAg/Qwj/vEvpCkNYgpygxjzpnlA+8iPPktJt///Ef7rAtUuCvvDLjixClIzGhz2KT0Bdjoq+0ar1RAtjsnGl20UyLOPn3rW81F/a57XWvOykH60UZkdCXiKpPGVCUvu95cuGFrQT+cYdfynWeelE+JPQlooy11ywou5Bt2+b+4Q9HC/xb3vKEH3jg6zta2rBVQVj2/BOtkdCXiF5cXq8RVRGmTZvc3/jGaIH/y78M5orvlDhdU6v0RiQaI6EvEarRV0OYHnggWtzB/etfT+ZcrSoH+k/1BnGFXvPR58jcJFYzMzOY2bzfkphcrEy0Ozd+kbjxxmCCsV/5leZx1qwJpP53fzeZcw4ODkaGF3FiOZEfEvqcmFvdaW46X3d/ReyHhoaarvJUVcomTO5w7rmBwJ98cuM4hx4KGzcGcY9MeA7XVjOPtioIRI8Rp9qf9taLrpteeLVux+delvx46SX3U06Jds+cckoQL22i8nfVqlUdDy4T5QH56ItN1Rtg2/W5F91H/5OfuB96aLTA//Vfd9fAmhTNpo9YtWpV3qaJhJHQF5yy1GA7pZPrK2Kvm3vvjRZ3cL/hhmTOldT1V/2/JXYhoS84Ra/BdkvZ31iuvba1wK9dm9z5Ov0/NCocyp73Ij4S+hJQxBpsUpSxVjk7G/RvjxL3N74x6Cfvnuz96/QNqFHhUKvVSpf3ojMk9KJtkhSuMr2xbN3q/v73Rwv8hz8cjHSdI+nr66QW3qxwqNVqpcl70R0SetEWac3ZXuQ3lg0b3A84IFrgL7yw8bFJv7F0kl6r+fyLnPciGST04hXiPPRldLV0yve/Hy3uEMwyGUU7NfA4+d9JQdtL90w0RkIv3D2+gPRCA95VV0WLe3+/+8MPx0srrsimtVB6u2mLaiKhF+4eX5CqWjvcuTNYoSlK4N/6Vvdnn20v3bgim3a+ykXT20johbvHr6k3WwO1VquVUjy2bAnWWI0S+D/6I/ft2zs/RxyR7YU3JZEfEnrh7u3VKCcmJhp2zSuTO2B62n358miBv+ii7Oyp6puSKAZxhV6TmlWcVpNf1TM6OsqyZct2Cy/DLJJ33RVMMDY8DM880zjO7bcHUv+JT2RnVzv5L0RqxCkN0t6qXKMvgg+1HRvK5mq49NLo2vtee7mvX5+vjUX4D4hqQswavQVx82VkZMSnpqbyNiNx5qYirp9nfenSpYWegnhufvyFDA0NMT09nb1BDdi5E/7sz+Cii5rHeec74eab4dWvzs4uIbLGzNa4+0ireHLdpEgZF9No5GoA2LJlC5OTk12nP7fYyqJFixgeHm4rzZ//PBDwxYubi/yf/Ans2AF33imRF+IV4lT7096q6ropmxtkjrQaZTvt971+vfuyZdEumksv7dgsIUoLct3kTxncIM1Iw/Z20/zOd+DYY6PT/N734JhjOjJHiNKTmOvGzC43s5+a2YN1YeeY2ZNmdl+4nVD321lmtt7M1pnZcZ1fQvkpc4+LuEv7teOKiZvmRRcFPWiaifyKFTA9HdTl60W+G7eQEJWmVZUfeBdwJPBgXdg5wKcbxD0cuB9YAhwEPAr0tTpHVV037uXtcRGn/3e7rpioNLdvd//IR6LdM+95TzAQqhGaDkD0IiQ5YAoYjin0ZwFn1X2/FfjPrdKvstCXlTjC2e5goEZp7rnnL/lBBz0TKfCf+UwwlUEUZRmYVNaCXxSTLIR+GlgLXA7sE4ZfBHy4Lt5lwClN0hwDpoCpwcHBbHKlR0hKTFql00lj81ya8MsO2yMF/qqr4ttahoZvvXWIpElb6F8L9BH4+M8FLg/D/7aB0H+wVfqq0SdHlmLSSS36llui3TMQTCOchS1ZUwYbRbmIK/Qd9aN396fdfae7zwKXAm8Lf9oAHFgX9QDgqU7OUVXSbjDMsu9+O43NF14YNLCecMJuPwFw4IGwYUMg9UcfnYwtZsbMzExhGmbjNkYLkThxSgN2r9GvrNv/H8A14f4RzG+MfYweb4ytJ4vadtYujCj3zrZt7r/3e9G19xNPDJbyS8LdtMstxG75UAQXSbMafa1Wk99edARJuW6Aq4GNwHaCGvtHgKuABwh89DctEP7VBL1t1gHHxzGiV4Q+i1f3IrgHNm1yP/zwaIE/++xgMW735AvAIuRBIxpd58DAgPf39xeuUBLlIDGhz2LrFaHPoradZ4Pf2rXR4g7u1167+3FJC3ORG2YXvrk0GoFchEJJlAMJfQR5dXHLqqaZ9fV985utBf7ee5sfn7QwF7VG34giF0qi+Ejom5BnjbdK3etmZ90/97locT/sMPef/KR1WkkLc5nyuUyFkigeEvom5P1glX3AzEsvuf/O70QL/Ic+FMSLSxrCXJZ8LlOhJIqHhL4JelXujI0b3Q8+OFrg9977PL/qqnQGZ1WZXr520R0S+ibkXaMvG2vWRIt7sP12y9qoxKx86J4VHwl9E6r8qpzkg3n22a0FfuXK98QqNKuc50lQREHVPSsHEvoIivhgdUsSD+bsrPvRR7cS+Psddg3wieMGy+Itqqz3tKiCmsebb1nvYZ5I6HuMbh7M559vXXuHKxwWzxPzuOdMu12kqGIZh6K6EvMYYV3We5gnEvoeo5MH84c/bC3wy5Zd3VSIGj2cEAzp72Y643YpqljGoaidA7LO0zLfwzyJK/RaHLwiDA4Oxg6//vpggrHDD2+e3pe/HEj9xRfvbDpx2ejoKOPj49RqtXm/b968mbGxsVcmEkt7pa0yTxbWzn3LkqxXRyvzPSwFcUqDtDfV6Lsnzqvvpz7VugZ/112N047yncapjaXpfy1zbbDILossfeZlvod5glw3vUejB3PnTvcjjmgt8E891fl583Y/FFks46BGyPLfw7yQ0Pc4mze3FvfXvS6YSniOTgWnCLUxiWX50T1sHwl9j/KDH7QW+NNP3/24bmpUqo0JkQ9xhV6NsRXhqquCBta3vKV5nMsuC6T+a1/b/bduVqaaa5QdGhrCzBgaGmJ8fJzR0dHI4xqttpX2ClxC9CIWFAr5MjIy4lNTU3mbUUo+9jG45JLoOFNTcNRR0XEWLVpEo/+CmTE7O9uFhY2ZnJxkbGxsXuHS39+Pu7Njx45XwgYGBrj88stbFhpC9CJmtsbdR1rFU42+hOzcCaedFtTgo0R+zz0HmZiYbCnykH03v0ZvENu3b58n8gDbtm3jjDPOSMUGIXoFCX0Baea+eP55eMc7YPFiuOaaZkevA/oA48UXn4i9KHijftMAW7ZsScV90k7/6M2bN8eOK9ePEA2I48hPe+uFxti4PQoaNWzusccbfcmS7S0aWS/quovjxMREw6Xt0mhYbdZTp9kW1341CrdGvVuqA+p1UxzaEaD5Anhsyx40f//3jY6L7uIY9aA3S6evry9RYWg2fUKjrVarxUqzCN08i44Kw2ohoS8Q7QhQMPjok5Hivt9+7jMz84+L+wC3itds8FMawrCwwFm1apX39/fPO1d/f3/sc+U9cKsMqDCsFhL6AhFHgLZvd//DP4yuvR93nPuWLc3PE+eVvNWDHtelkpYwdONWkIi1RoVhtZDQF4goAXr2WfejjooW+MWLL5y3RF83YtjqQY/rUimiMMgt0RoVhtUiMaEHLgd+CjxYF7YvcBvwSPi5TxhuwJeA9cBa4Mg4RmQh9Hk2QDVuYH2zL1q0M1LgYfQVl8ac7bVazQcGBiLFrBMffP2DXn98X19fqYRBDY3RqDCsFkkK/buAIxcI/fnAmeH+mcB54f4JwLdCwX87cHccI9IW+iL8uecECI5vIe7ud98dbXuU8La61nbzogh5J5JFhWF1SNR1AwwvEPp1wMpwfyWwLty/BDitUbyoLW2hL8Lr6gUXRIv70JD7k0/Gt72ZK6XdGnv9g95uuBAiX9IW+ucW/P6z8PNm4Ji68NuBkVbppy30eTVAvfyy+2mnRQv8SSe5v/hi+7Y3E/JOr1U1dyHKR1yhT3pkrDUI84YRzcbMbMrMpjZt2pSwGfPJenj/pk3B6k1LlsDVVzeO81d/BbOzcMMNsMcezdOKY2P9yj+dXms3k5qVAY2YFb1Mp0L/tJmtBAg/fxqGbwAOrIt3APBUowTcfdzdR9x9ZMWKFR2aEY+slkVbuzaYf2a//eDhhxvHue66oC5/zjlB3FY0sr2/v59arTZvpkiA4eFhZmZmsAUJDwwMsGXLlkiRq/JSbnMTqM3MzODuzMzMzFvqUIjKE6faz+6umwuY3xh7frj/PuY3xt4TJ/2y97r5xjei3TMQzBOflu2N3C5zLpxarbbbIKRGLpk82jGy8v0XoY1GiDQgwV43VwMbge0ENfaPADUC//sj4ee+YVwD/hZ4FHiAGP55z0jok2Z21v2zn40W9ze8wf3pp9O3JUrI4opckj76OAKeZZuABgmJqpKY0GexlUnoX3zR/QMfaFWDv9oHBw/NrCEzSsjaEbkkathxBTzLWrZq9KKqSOgTZuNG94MOihb4/v6zc+m1kkSNPgtb6smylq0eRaKqSOgTYmqqVe3d/aab8q01RglZ1iIXV8Czzi+NBRBVRELfJVdf3VrgH3xwV/y8/cBRQpalyKXRJiCRFqIxEvoOmJ11P+usaHF/05vcn3lm92PlBw5IWsDldhGiORL6NvjFL9yPPz5a4E8/3X3btuZpSJB20Wie+U5r5CpAhWiOhD4GTzzhvnJltMB/4Qvx05OLYXe6LQDzdokJUWQk9BH8279Fizu4/9M/ZWpSxxS9cOm2Rq4avRDNiSv0Sc91U2juvjuYduDXfq3x70uWwLp1gdQfd1y2tnVCGYb2dzu1QlbTVwhRZXpK6N/+9sbhRx8NP/sZvPQSvP712drUDWWYiKzbCeVGR0cZHx9naGho3tw+o6OjSZopRKXpKaFfyB//MezYAd//Puy9d97WtE8ZJiJLokY+OjrK9PQ0s7OzTE9PS+SFaJOeEvp//Vc48kj4ylcC98zFF0NfX+vj8pjiNs45s55+uROSqpFrmmEhuiCOIz/tLe/ulVHk0W0y7jlXrVq1W6+UKnbpVNdVIRqDet0kQx69PuKcs9nUxKtWrWqZftF76ixEPW+EaIyEPiHy6Mcd55ydil/RasdxCh31pW9O2QptkSwS+oQoao2+U/Gr1Wqx3hayEI8iTmlcJopWaIvskdAnRFF99M3Er1arRabb6Jj6AiLL601jArReQgWgkNAnSDc13E6PjbN84MIlAgEfGBhoeo5mwlAvDlmKR9aLolQNubSEhL4ApF0TjeOGqaeZMACv2JSleKhG2h3KPxFX6HswpXOxAAAHjUlEQVSqH33WpD1y9dlnn20Y3mzAVLP+9bVa7ZV+7Vn2zT/hhBPaChfz0fQQIi4S+jaZnJxk+fLlmBlmxvLly5sO3kl75Gq7otxMGL74xS/Oi9Pf3z8vTn9/f1fi0Wyw0y233NIwfrPwqLR6EU0PIWITp9qf9lYW183ExIQPDAzs9qrc39/f0B2T9qt1J66hOL7/hdcY5ffvxsZ23URqlBViPshHnywTExPe19fXsjFz4TFpC1PSjZRJF05R6bV7LvmkhZiPhD5BGgl2O7XQMvUWSboxNiq9dgtC9TIRYj4S+gSJ6pZY1FplpwVMVjX6uTTbWWawKjX6shX+orhkIvTANPAAcN/cCYF9gduAR8LPfVqlU3Shj+qWGOWjz4tuXEbN3l5qtVpH19jqbSjKrkZrz5bdR692BpEkWQr98gVh5wNnhvtnAue1SqeIQl8vMlG++U4FME26rflOTEw07KPfqSDN5WU7b0PNBLGbhcaLQFXeSkQxyFPo1wErw/2VwLpW6RRB6OuFvVarNexdU5ZaWBK+7FbC3Mm1t2NXVQVR7QwiSbIS+h8D9wJrgLEw7LkFcX7W5NgxYAqYGhwcTD1DoojT2Ap4X19fKWqSSYhkK3dVJwVdO3ZVVRCrWoCJfMhK6H8p/NwPuB94V1yhr9/yrtHHaWxtJTJFamBLwg+cRgN0K7viuMvKLojy0YskyUTo5yUE5wCfpoSum1a111YiU8SHt9uCp5supZ3YFed8eedpUhSpUiDKTepCD7wK2Ktu/9+A9wIXML8x9vxWaeUt9HFqr1EiU9XX8U4aUTul2XnK4i4TIg+yEPqDQ3fN/cBDwOowvAbcTtC98nZg31Zp5S30jWqT/f39XqvVYolMVf3Jc2TxxlL1PBQiDTJ33XSz5S307t29Tle1Rl9P2u6GXshDIZJGQp8RSfc571WK2M4hRNGJK/SaprgLJicnGRsbY/PmzfPCa7WapottE025K0R6WFAo5MvIyIhPTU3lbUbbDA8PMzMzs1v40NAQ09PT2RskhOgpzGyNu4+0iqcafRekvbCIEEIkgYS+C7Jcdk8IITpFQt8FWrNTCFEGJPRdoAZEIUQZUGOsEEKUFDXGCiGEACT0QghReST0QghRcST0QghRcST0QghRcQrR68bMXiBYsETAcuCZvI0oEMqPXSgvdqG8CBhy9xWtIi3OwpIYrIvTRagXMLMp5cUulB+7UF7sQnnRHnLdCCFExZHQCyFExSmK0I/nbUCBUF7MR/mxC+XFLpQXbVCIxlghhBDpUZQavRBCiJTITOjNbF8zu83MHgk/92kS75/M7Dkzu3lB+EFmdnd4/NfNbCAby5Onjbw4PYzziJmdXhf+XTNbZ2b3hdt+2VmfDGb23vAa1pvZmQ1+XxLe5/XhfR+u++2sMHydmR2Xpd1p0GlemNmwmb1Y9z+4OGvb0yBGfrzLzO41sx1mdsqC3xo+Mz1PnIVlk9iA84Ezw/0zgfOaxDsWOBG4eUH4tcCp4f7FwKqsbM8jL4B9gcfCz33C/X3C374LjOR9HV1cfx/wKHAwMADcDxy+IM7HgYvD/VOBr4f7h4fxlwAHhen05X1NOeXFMPBg3teQQ34MA78KXAmcUhfe9Jnp9S1L181JwBXh/hXAyY0iufvtwAv1YWZmwG8C17c6viTEyYvjgNvc/Vl3/xlwG/DejOxLm7cB6939MXffBlxDkCf11OfR9cCx4f/gJOAad3/Z3X8MrA/TKyvd5EUVaZkf7j7t7muB2QXHVvmZ6Yoshf617r4RIPxsx91QA55z9x3h9w3A/gnblyVx8mJ/4Im67wuv+e/C1/WzS/jQt7q2eXHC+/48wf8gzrFlopu8ADjIzH5gZv9iZu9M29gM6Ob+Vu2/kRiJjow1s28Dr2vw0+puk24QVujuQgnkRdQ1j7r7k2a2F/APwH8jeI0tC3HuZ7M4pfsvtKCbvNgIDLr7ZjM7CrjBzI5w958nbWSGdHN/q/bfSIxEhd7d393sNzN72sxWuvtGM1sJ/LSNpJ8B9jazxWGN5gDgqS7NTZUE8mID8Bt13w8g8M3j7k+Gny+Y2d8TvO6WSeg3AAfWfW90P+fibDCzxcBrgGdjHlsmOs4LDxzTLwO4+xozexR4PVDm5dq6ub9Nn5leJ0vXzU3AXCv46cCNcQ8M/9B3AHMt7G0dX0Di5MWtwG+Z2T5hr5zfAm41s8VmthzAzPqB9wMPZmBzkvw/4LCwJ9UAQQPjTQvi1OfRKcB3wv/BTcCpYU+Ug4DDgHsysjsNOs4LM1thZn0AZnYwQV48lpHdaREnP5rR8JlJyc5ykVWrL4FP8XbgkfBz3zB8BPi/dfG+B2wCXiQooY8Lww8meKDXA9cBS/Juyc4gL/4wvN71wB+EYa8C1gBrgYeAL1LCXifACcCPCHpYrA7DPgf8dri/R3if14f3/eC6Y1eHx60Djs/7WvLKC+CD4X/gfuBe4MS8ryWj/HhrqA2/ADYDD9Udu9szo801MlYIIaqORsYKIUTFkdALIUTFkdALIUTFkdALIUTFkdALIUTFkdALIUTFkdALIUTFkdALIUTF+f+ih4r/4lAkowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x171d858a470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_testset, y_testset, color='black')\n",
    "plt.plot(X_testset, LinReg.predict(X_testset), color='blue', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the prediction line will be based off of the <b>training</b> data. In comparsion, you can see a slight offset, but in general it reflects a good <b>prediction</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler for Mac users](https://cocl.us/ML0101EN_SPSSMod_mac) and [SPSS Modeler for Windows users](https://cocl.us/ML0101EN_SPSSMod_win)\n",
    "\n",
    "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0101EN_DSX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Additional Resources\n",
    "<br>\n",
    "K-Nearest Neighbors Algorithm: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm \n",
    "<br><br>\n",
    "Cross-Validation: http://scikit-learn.org/stable/modules/cross_validation.html \n",
    "<br><br>\n",
    "Model Evaluation: http://scikit-learn.org/stable/modules/model_evaluation.html \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2016 [Big Data University](https://bigdatauniversity.com/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
